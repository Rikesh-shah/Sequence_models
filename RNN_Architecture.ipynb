{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PicTOJviwndU"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(3, input_shape=(4,5)))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "P1msKuscC0V_",
        "outputId": "dfcae393-d56d-4ae8-edfc-19918c0a7e75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m4\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31\u001b[0m (124.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (124.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31\u001b[0m (124.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (124.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[0].shape)\n",
        "model.get_weights()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbN4Fw3PDESJ",
        "outputId": "209b7e7c-15e6-4c59-d686-748bb963e159"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.7222958 , -0.39231452,  0.8102338 ],\n",
              "       [-0.22253048,  0.51329476, -0.11307728],\n",
              "       [ 0.6616803 , -0.03424352, -0.5571724 ],\n",
              "       [-0.75588584, -0.19022644, -0.36317575],\n",
              "       [-0.33432722,  0.39289182, -0.86212236]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[1].shape)\n",
        "model.get_weights()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQEE_vStDgZ1",
        "outputId": "ad1a5fdf-da00-4d3f-8070-ae27b177554d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.92152417,  0.19919482, -0.33333844],\n",
              "       [ 0.27871045, -0.25844836, -0.92494595],\n",
              "       [ 0.27039522,  0.945265  , -0.18264875]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[2].shape)\n",
        "model.get_weights()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTQP2q-hDoux",
        "outputId": "85b58525-e9bf-4bc4-a062-5ce45f2a7178"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[4].shape)\n",
        "model.get_weights()[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqbxw-LJDuag",
        "outputId": "75cf26a2-d55a-43fe-b1fa-2fbe049b09fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "FJ-U18RqDyDj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary"
      ],
      "metadata": {
        "id": "pi7m7YZKEsJE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(n_inputs, n_neurons, batch_first=False)\n",
        "        self.fc = nn.Linear(n_neurons, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "model1 = SimpleRNN(5, 3)\n",
        "\n",
        "# Create a sample input\n",
        "input_seq = torch.randn(4, 1, 5)\n",
        "\n",
        "summary(model1, input_size=(4, 1, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFiZ_V5UGgvr",
        "outputId": "0682729a-3094-4e3a-9212-4a9182261e25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SimpleRNN                                [1, 1]                    --\n",
              "├─RNN: 1-1                               [4, 1, 3]                 30\n",
              "├─Linear: 1-2                            [1, 1]                    4\n",
              "├─Sigmoid: 1-3                           [1, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 34\n",
              "Trainable params: 34\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get weights\n",
        "for name, param in model1.named_parameters():\n",
        "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
        "    print(param)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "output = model1(input_seq)\n",
        "print(\"Output Shape:\", output.shape)\n",
        "print(\"Output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_BBqEfNG3Vw",
        "outputId": "77c31141-2341-4f63-9e31-8ff2159947c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: rnn.weight_ih_l0, Shape: torch.Size([3, 5])\n",
            "Parameter containing:\n",
            "tensor([[ 0.4702, -0.2662, -0.1614,  0.3212,  0.5687],\n",
            "        [ 0.1928, -0.2423, -0.2307,  0.3806,  0.3177],\n",
            "        [ 0.4798,  0.3733,  0.3049, -0.0479,  0.1697]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: rnn.weight_hh_l0, Shape: torch.Size([3, 3])\n",
            "Parameter containing:\n",
            "tensor([[-0.4786, -0.5299, -0.0424],\n",
            "        [ 0.3167,  0.1553,  0.2257],\n",
            "        [ 0.2022, -0.2553, -0.3498]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: rnn.bias_ih_l0, Shape: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([-0.5165,  0.1109,  0.0217], requires_grad=True)\n",
            "--------------------\n",
            "Layer: rnn.bias_hh_l0, Shape: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([ 0.3422,  0.4552, -0.3813], requires_grad=True)\n",
            "--------------------\n",
            "Layer: fc.weight, Shape: torch.Size([1, 3])\n",
            "Parameter containing:\n",
            "tensor([[-0.3777, -0.1570, -0.4224]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: fc.bias, Shape: torch.Size([1])\n",
            "Parameter containing:\n",
            "tensor([0.4446], requires_grad=True)\n",
            "--------------------\n",
            "Output Shape: torch.Size([1, 1])\n",
            "Output: tensor([[0.7047]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(n_inputs, n_neurons, batch_first=False)\n",
        "        self.fc = nn.Linear(n_neurons, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model2 = SimpleLSTM(5, 3)\n",
        "\n",
        "# Create a sample input\n",
        "input_seq = torch.randn(4, 1, 5)\n",
        "\n",
        "summary(model2, input_size=(4, 1, 5))"
      ],
      "metadata": {
        "id": "9qFzvJo7HfDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a817df-289f-4b8f-f031-d62565f75397"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SimpleLSTM                               [1, 1]                    --\n",
              "├─LSTM: 1-1                              [4, 1, 3]                 120\n",
              "├─Linear: 1-2                            [1, 1]                    4\n",
              "├─Sigmoid: 1-3                           [1, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 124\n",
              "Trainable params: 124\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get weights\n",
        "for name, param in model2.named_parameters():\n",
        "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
        "    print(param)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "output = model2(input_seq)\n",
        "print(\"Output Shape:\", output.shape)\n",
        "print(\"Output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8N2bKkl7gTK",
        "outputId": "c53fd10e-9578-43f0-bfe7-a44457ee834b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: lstm.weight_ih_l0, Shape: torch.Size([12, 5])\n",
            "Parameter containing:\n",
            "tensor([[-0.1099, -0.0776, -0.0163,  0.3198,  0.4249],\n",
            "        [-0.0601,  0.4510, -0.5650,  0.2973, -0.5478],\n",
            "        [ 0.5100, -0.0415,  0.5473,  0.2193, -0.3519],\n",
            "        [ 0.4817, -0.0470,  0.0167,  0.2843,  0.4659],\n",
            "        [-0.1825, -0.4112,  0.2079,  0.2790, -0.3474],\n",
            "        [-0.4749, -0.2246, -0.5095, -0.5080,  0.0958],\n",
            "        [-0.0195,  0.3965, -0.1218,  0.4515, -0.4201],\n",
            "        [ 0.3152,  0.1049,  0.4333,  0.3988,  0.4020],\n",
            "        [-0.2913,  0.4573,  0.1957,  0.5670,  0.2506],\n",
            "        [ 0.3847, -0.1539, -0.0893, -0.3664, -0.0995],\n",
            "        [-0.5221,  0.2963, -0.3976, -0.3920,  0.4182],\n",
            "        [ 0.1329,  0.1781, -0.5018,  0.0695, -0.4020]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: lstm.weight_hh_l0, Shape: torch.Size([12, 3])\n",
            "Parameter containing:\n",
            "tensor([[ 0.2071,  0.0940,  0.5196],\n",
            "        [ 0.5515,  0.2790,  0.2239],\n",
            "        [ 0.4291, -0.3637, -0.0406],\n",
            "        [ 0.3342, -0.4909,  0.1363],\n",
            "        [-0.2004, -0.3921,  0.1398],\n",
            "        [ 0.1451,  0.5527,  0.0031],\n",
            "        [ 0.2198,  0.1900,  0.2253],\n",
            "        [ 0.3124,  0.1487,  0.0596],\n",
            "        [-0.0387, -0.2056, -0.2226],\n",
            "        [ 0.4459,  0.2462,  0.3707],\n",
            "        [ 0.4680,  0.4977, -0.0935],\n",
            "        [ 0.1191,  0.0136,  0.5216]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: lstm.bias_ih_l0, Shape: torch.Size([12])\n",
            "Parameter containing:\n",
            "tensor([ 0.3557, -0.4891, -0.0656, -0.0840,  0.2702, -0.3153, -0.4320, -0.3849,\n",
            "         0.5293, -0.2714, -0.3775, -0.2244], requires_grad=True)\n",
            "--------------------\n",
            "Layer: lstm.bias_hh_l0, Shape: torch.Size([12])\n",
            "Parameter containing:\n",
            "tensor([-0.2254,  0.1274,  0.2230,  0.3098,  0.1824, -0.3047,  0.5583,  0.1714,\n",
            "         0.2661, -0.5602,  0.1149, -0.0727], requires_grad=True)\n",
            "--------------------\n",
            "Layer: fc.weight, Shape: torch.Size([1, 3])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1677, -0.4090, -0.0747]], requires_grad=True)\n",
            "--------------------\n",
            "Layer: fc.bias, Shape: torch.Size([1])\n",
            "Parameter containing:\n",
            "tensor([-0.1328], requires_grad=True)\n",
            "--------------------\n",
            "Output Shape: torch.Size([1, 1])\n",
            "Output: tensor([[0.4687]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpBierhv8biB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}