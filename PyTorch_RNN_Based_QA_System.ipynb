{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zmQqr1m-GR-7",
        "outputId": "4a3d97a9-b77c-4d62-be8d-9d14007bc613"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b790b0fb-0557-47c2-b4a3-a46fcaac4532\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b790b0fb-0557-47c2-b4a3-a46fcaac4532')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b790b0fb-0557-47c2-b4a3-a46fcaac4532 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b790b0fb-0557-47c2-b4a3-a46fcaac4532');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76c6a07d-19ce-4813-a3fc-077dbc41ced5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76c6a07d-19ce-4813-a3fc-077dbc41ced5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76c6a07d-19ce-4813-a3fc-077dbc41ced5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/100_Unique_QA_Dataset.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the dataset\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "51wZGHIJGYCk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('What is the capital of Germany?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Neagm045HkHk",
        "outputId": "a759afde-0c02-401d-b2fc-e5e25b9f2be3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'germany']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "vocab = {'<UNK>':0}"
      ],
      "metadata": {
        "id": "9ZHZBTHiGYFk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n",
        "\n",
        "  print(merged_tokens)"
      ],
      "metadata": {
        "id": "gHZk2RUYHxnM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OeaH_L3AH7gU",
        "outputId": "d50bbc32-2f6b-43ad-ff5d-e2dacc41c589",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what', 'is', 'the', 'capital', 'of', 'france', 'paris']\n",
            "['what', 'is', 'the', 'capital', 'of', 'germany', 'berlin']\n",
            "['who', 'wrote', 'to', 'kill', 'a', 'mockingbird', 'harper-lee']\n",
            "['what', 'is', 'the', 'largest', 'planet', 'in', 'our', 'solar', 'system', 'jupiter']\n",
            "['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius', '100']\n",
            "['who', 'painted', 'the', 'mona', 'lisa', 'leonardo-da-vinci']\n",
            "['what', 'is', 'the', 'square', 'root', 'of', '64', '8']\n",
            "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'gold', 'au']\n",
            "['which', 'year', 'did', 'world', 'war', 'ii', 'end', '1945']\n",
            "['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'world', 'nile']\n",
            "['what', 'is', 'the', 'capital', 'of', 'japan', 'tokyo']\n",
            "['who', 'developed', 'the', 'theory', 'of', 'relativity', 'albert-einstein']\n",
            "['what', 'is', 'the', 'freezing', 'point', 'of', 'water', 'in', 'fahrenheit', '32']\n",
            "['which', 'planet', 'is', 'known', 'as', 'the', 'red', 'planet', 'mars']\n",
            "['who', 'is', 'the', 'author', 'of', '1984', 'george-orwell']\n",
            "['what', 'is', 'the', 'currency', 'of', 'the', 'united', 'kingdom', 'pound']\n",
            "['what', 'is', 'the', 'capital', 'of', 'india', 'delhi']\n",
            "['who', 'discovered', 'gravity', 'newton']\n",
            "['how', 'many', 'continents', 'are', 'there', 'on', 'earth', '7']\n",
            "['which', 'gas', 'do', 'plants', 'use', 'for', 'photosynthesis', 'co2']\n",
            "['what', 'is', 'the', 'smallest', 'prime', 'number', '2']\n",
            "['who', 'invented', 'the', 'telephone', 'alexander-graham-bell']\n",
            "['what', 'is', 'the', 'capital', 'of', 'australia', 'canberra']\n",
            "['which', 'ocean', 'is', 'the', 'largest', 'pacific-ocean']\n",
            "['what', 'is', 'the', 'speed', 'of', 'light', 'in', 'vacuum', '299,792,458m/s']\n",
            "['which', 'language', 'is', 'spoken', 'in', 'brazil', 'portuguese']\n",
            "['who', 'discovered', 'penicillin', 'alexander-fleming']\n",
            "['what', 'is', 'the', 'capital', 'of', 'canada', 'ottawa']\n",
            "['what', 'is', 'the', 'largest', 'mammal', 'on', 'earth', 'whale']\n",
            "['which', 'element', 'has', 'the', 'atomic', 'number', '1', 'hydrogen']\n",
            "['what', 'is', 'the', 'tallest', 'mountain', 'in', 'the', 'world', 'everest']\n",
            "['which', 'city', 'is', 'known', 'as', 'the', 'big', 'apple', 'newyork']\n",
            "['how', 'many', 'planets', 'are', 'in', 'the', 'solar', 'system', '8']\n",
            "['who', 'painted', 'starry', 'night', 'vangogh']\n",
            "['what', 'is', 'the', 'chemical', 'formula', 'of', 'water', 'h2o']\n",
            "['what', 'is', 'the', 'capital', 'of', 'italy', 'rome']\n",
            "['which', 'country', 'is', 'famous', 'for', 'sushi', 'japan']\n",
            "['who', 'was', 'the', 'first', 'person', 'to', 'step', 'on', 'the', 'moon', 'armstrong']\n",
            "['what', 'is', 'the', 'main', 'ingredient', 'in', 'guacamole', 'avocado']\n",
            "['how', 'many', 'sides', 'does', 'a', 'hexagon', 'have', '6']\n",
            "['what', 'is', 'the', 'currency', 'of', 'china', 'yuan']\n",
            "['who', 'wrote', 'pride', 'and', 'prejudice', 'jane-austen']\n",
            "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'iron', 'fe']\n",
            "['what', 'is', 'the', 'hardest', 'natural', 'substance', 'on', 'earth', 'diamond']\n",
            "['which', 'continent', 'is', 'the', 'largest', 'by', 'area', 'asia']\n",
            "['who', 'was', 'the', 'first', 'president', 'of', 'the', 'united', 'states', 'george-washington']\n",
            "['which', 'bird', 'is', 'known', 'for', 'its', 'ability', 'to', 'mimic', 'sounds', 'parrot']\n",
            "['what', 'is', 'the', 'longest-running', 'animated', 'tv', 'show', 'simpsons']\n",
            "['what', 'is', 'the', 'smallest', 'country', 'in', 'the', 'world', 'vaticancity']\n",
            "['which', 'planet', 'has', 'the', 'most', 'moons', 'saturn']\n",
            "['who', 'wrote', 'romeo', 'and', 'juliet', 'shakespeare']\n",
            "['what', 'is', 'the', 'main', 'gas', 'in', 'earths', 'atmosphere', 'nitrogen']\n",
            "['how', 'many', 'bones', 'are', 'in', 'the', 'adult', 'human', 'body', '206']\n",
            "['which', 'metal', 'is', 'a', 'liquid', 'at', 'room', 'temperature', 'mercury']\n",
            "['what', 'is', 'the', 'capital', 'of', 'russia', 'moscow']\n",
            "['who', 'discovered', 'electricity', 'benjamin-franklin']\n",
            "['which', 'is', 'the', 'second-largest', 'country', 'by', 'land', 'area', 'canada']\n",
            "['what', 'is', 'the', 'color', 'of', 'a', 'ripe', 'banana', 'yellow']\n",
            "['which', 'month', 'has', '28', 'days', 'in', 'a', 'common', 'year', 'february']\n",
            "['what', 'is', 'the', 'study', 'of', 'living', 'organisms', 'called', 'biology']\n",
            "['which', 'country', 'is', 'home', 'to', 'the', 'great', 'wall', 'china']\n",
            "['what', 'do', 'bees', 'collect', 'from', 'flowers', 'nectar']\n",
            "['what', 'is', 'the', 'opposite', 'of', 'day', 'night']\n",
            "['what', 'is', 'the', 'capital', 'of', 'south', 'korea', 'seoul']\n",
            "['who', 'invented', 'the', 'light', 'bulb', 'edison']\n",
            "['which', 'gas', 'do', 'humans', 'breathe', 'in', 'for', 'survival', 'oxygen']\n",
            "['what', 'is', 'the', 'square', 'root', 'of', '144', '12']\n",
            "['which', 'country', 'has', 'the', 'pyramids', 'of', 'giza', 'egypt']\n",
            "['which', 'sea', 'creature', 'has', 'eight', 'arms', 'octopus']\n",
            "['which', 'holiday', 'is', 'celebrated', 'on', 'december', '25', 'christmas']\n",
            "['what', 'is', 'the', 'currency', 'of', 'japan', 'yen']\n",
            "['how', 'many', 'legs', 'does', 'a', 'spider', 'have', '8']\n",
            "['which', 'sport', 'uses', 'a', 'net,', 'ball,', 'and', 'hoop', 'basketball']\n",
            "['which', 'country', 'is', 'famous', 'for', 'its', 'kangaroos', 'australia']\n",
            "['who', 'was', 'the', 'first', 'female', 'prime', 'minister', 'of', 'the', 'uk', 'margaretthatcher']\n",
            "['which', 'is', 'the', 'fastest', 'land', 'animal', 'cheetah']\n",
            "['what', 'is', 'the', 'first', 'element', 'on', 'the', 'periodic', 'table', 'hydrogen']\n",
            "['what', 'is', 'the', 'capital', 'of', 'spain', 'madrid']\n",
            "['which', 'planet', 'is', 'the', 'closest', 'to', 'the', 'sun', 'mercury']\n",
            "['who', 'is', 'known', 'as', 'the', 'father', 'of', 'computers', 'charlesbabbage']\n",
            "['what', 'is', 'the', 'capital', 'of', 'mexico', 'mexicocity']\n",
            "['how', 'many', 'colors', 'are', 'in', 'a', 'rainbow', '7']\n",
            "['which', 'musical', 'instrument', 'has', 'black', 'and', 'white', 'keys', 'piano']\n",
            "['who', 'discovered', 'the', 'americas', 'in', '1492', 'christophercolumbus']\n",
            "['which', 'disney', 'character', 'has', 'a', 'long', 'nose', 'and', 'grows', 'it', 'when', 'lying', 'pinocchio']\n",
            "['who', 'directed', 'the', 'movie', 'titanic', 'jamescameron']\n",
            "['which', 'superhero', 'is', 'also', 'known', 'as', 'the', 'dark', 'knight', 'batman']\n",
            "['what', 'is', 'the', 'capital', 'of', 'brazil', 'brasilia']\n",
            "['which', 'fruit', 'is', 'known', 'as', 'the', 'king', 'of', 'fruits', 'mango']\n",
            "['which', 'country', 'is', 'known', 'for', 'the', 'eiffel', 'tower', 'france']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo7Cg8ZjI42U",
        "outputId": "d0c95cd7-9e14-41f2-8ebb-2b1b2b4e0a9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to numerical indices\n",
        "def text_to_indices(text, vocab):\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "MwFskTaIGYIL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices('What is transformer', vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGF953BMGYKr",
        "outputId": "af0e5eb5-db7b-4d8b-da58-ca861e89d516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "AYnmdjzEGYND"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "r8jH1tiLGYPr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)"
      ],
      "metadata": {
        "id": "qC4N94B8GYST"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "id": "XCd39KS4GZgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55fdc893-cf2b-4750-a1af-f3f752dcd879"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "zn2lInWiGZjj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question , answer in dataloader:\n",
        "  print(question, answer)"
      ],
      "metadata": {
        "id": "bjPxPhk9GZot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "bc4f74f2-2e08-4117-a9e0-d5536a923f6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
            "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "mgAp2rb9GZrU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedded_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "1xEzJb1rGZwU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "Q2RFA4FiGZy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bde81e8-3b7e-4767-a097-a88b40b257dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(330, embedding_dim=50)"
      ],
      "metadata": {
        "id": "zsVcFdREGZ3c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = x(dataset[0][0])"
      ],
      "metadata": {
        "id": "8fs7pm8QGZ6M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slCXG-n7QCt6",
        "outputId": "57069dea-2c96-4dcb-d8ef-12ed757c5e9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1321,  0.0577, -1.3952, -1.4694, -0.3391, -1.0252,  1.2401, -0.4959,\n",
              "         -2.8411, -0.8803,  0.5460, -1.3759, -0.4237, -0.7808, -0.2029,  0.0983,\n",
              "         -0.2088,  0.4787,  0.1558, -0.5461, -0.7556,  0.0787,  0.0142, -1.5852,\n",
              "          1.3602, -0.5277, -0.3850,  0.3840, -1.4967, -0.5771, -1.0179,  1.2716,\n",
              "         -0.3192,  0.0622, -0.0763, -0.7493, -0.9779,  0.6055,  0.6455,  0.1201,\n",
              "          0.6821,  0.3985, -0.3047, -1.5467, -0.6077,  0.8067,  0.2489,  1.1432,\n",
              "          0.4449, -0.6554],\n",
              "        [-0.3718, -1.2859,  1.2903,  1.0654,  0.0896,  0.7027, -0.4526,  0.3327,\n",
              "          0.2497, -0.2854,  0.6703,  0.3828,  0.4687, -0.1043,  0.2145,  0.2046,\n",
              "          1.1169,  1.0346,  1.7669,  0.5151,  1.5036,  0.4370, -0.5905, -1.1102,\n",
              "          1.1207,  0.7832,  2.4049,  0.7481,  0.2178, -0.6416,  0.4640, -0.7941,\n",
              "          0.1818, -0.9757,  0.6126, -0.4273, -0.2047, -2.8126,  0.3320,  0.6471,\n",
              "          1.0469, -0.1324, -0.1218,  1.8553, -1.0518,  0.1093, -1.0803, -0.7977,\n",
              "         -1.3663, -1.8138],\n",
              "        [-0.1993, -0.5410,  0.1411,  1.5997, -2.5014,  0.0258,  1.1529,  0.9598,\n",
              "          0.4035,  1.0930, -0.3097, -0.4928, -0.2043, -0.5043, -0.1681,  0.8693,\n",
              "          0.9107, -0.5813,  0.9139, -0.9140, -0.0278, -2.2189,  1.0286, -1.4784,\n",
              "         -1.4273,  0.3303, -0.4521, -0.9499, -0.3423,  0.7925,  1.2612, -0.3294,\n",
              "          0.0076, -0.1480,  0.1326, -1.3477,  0.4925, -0.1429, -0.7050, -0.5550,\n",
              "          0.1477, -1.9166,  0.9141,  0.6238,  0.3762,  0.0972, -0.5978,  1.3613,\n",
              "         -0.8912, -0.8693],\n",
              "        [-0.0740,  0.0459, -1.5738,  0.4367,  0.7105, -0.0844, -1.2165, -0.5782,\n",
              "         -1.1243,  0.0335, -1.7763, -0.9351,  2.4070,  2.7412, -0.3161,  1.9630,\n",
              "         -0.1345, -0.1096, -0.0578, -1.5280,  0.3015,  0.8626,  0.7333,  1.0386,\n",
              "          1.4690,  0.6143,  0.1109,  0.3951,  1.3234,  0.9284,  0.0826,  0.3072,\n",
              "         -1.3762, -0.1365, -1.9068, -1.2077, -1.4002, -0.2597, -0.2871,  1.6802,\n",
              "          0.8700, -0.3319, -1.1180,  0.2825,  1.0668,  0.8877,  0.3886, -1.5795,\n",
              "         -0.1731, -0.6414],\n",
              "        [-1.1318, -0.0879, -1.0160,  0.7753,  0.5688, -1.8526, -0.3262,  0.0995,\n",
              "          0.0097, -0.4060,  0.8456, -0.1520, -1.7982,  0.7214, -0.0131, -0.2027,\n",
              "         -0.9086, -1.2967, -1.4654,  1.0916, -0.2526, -0.6521,  1.3609,  0.9553,\n",
              "         -1.0287,  0.8402,  1.0871,  1.0781,  0.8349,  0.2633, -1.3857, -1.0237,\n",
              "         -0.8356,  1.7471, -0.2261,  1.0057, -0.6343, -0.5003, -2.1040,  0.1224,\n",
              "         -0.7851,  0.8810,  0.1367,  1.2199, -2.3889, -0.7803, -1.8511, -1.4999,\n",
              "          1.0229,  0.0609],\n",
              "        [ 0.7860,  0.1329, -1.4423, -0.0551,  0.4366, -1.4184, -0.4966, -0.2816,\n",
              "         -0.3383,  0.0928, -0.1049, -1.1889, -0.6457, -1.1349, -0.6706, -1.6096,\n",
              "         -0.7004,  2.6594, -0.0528,  0.4991, -1.0166,  0.9014,  0.5489,  0.7658,\n",
              "          0.4468,  0.7570,  0.6305, -1.0293, -0.2708, -0.0882, -1.1168,  2.7724,\n",
              "         -0.4979,  2.1942,  0.3334,  1.3418,  0.0634, -1.4178, -1.0290, -1.1701,\n",
              "         -0.5993, -0.9844, -0.1865,  0.0440, -1.2816, -0.8946,  0.3649,  0.7616,\n",
              "         -2.0318,  0.8453]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50,64)"
      ],
      "metadata": {
        "id": "DA066K6-GZ-8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)"
      ],
      "metadata": {
        "id": "EBIJrIxKGaBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "10f53095-e6ea-405c-9b3e-92f9d6254780"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.3641, -0.1376,  0.1153,  0.4903,  0.3849,  0.0989,  0.1562,  0.5266,\n",
              "          -0.7186,  0.2070,  0.4730, -0.1899,  0.1854,  0.0235, -0.1557, -0.4728,\n",
              "           0.8315,  0.0749, -0.2166, -0.1797, -0.6919, -0.0848,  0.0412, -0.0344,\n",
              "          -0.4857, -0.2606, -0.4574,  0.1818,  0.4927,  0.2309,  0.0514, -0.4532,\n",
              "          -0.3192,  0.2922,  0.4085,  0.0636, -0.5820,  0.1914, -0.4224,  0.0191,\n",
              "          -0.1748, -0.1340, -0.6995, -0.4353, -0.6629,  0.1000,  0.4199,  0.0825,\n",
              "          -0.5049,  0.4666,  0.8458, -0.4064,  0.5511,  0.1629,  0.4182, -0.2245,\n",
              "           0.4360, -0.4322, -0.2136,  0.5043,  0.7262, -0.3869, -0.5804,  0.2838],\n",
              "         [ 0.3124, -0.3005, -0.5634, -0.5532, -0.7346,  0.4649, -0.8348, -0.8940,\n",
              "           0.6979, -0.4850, -0.6024, -0.0120,  0.2220, -0.2009, -0.0115, -0.6741,\n",
              "          -0.2948, -0.2965,  0.6888, -0.4391,  0.4967, -0.8518,  0.2915,  0.6102,\n",
              "          -0.6735,  0.2762,  0.1277,  0.3226, -0.7815, -0.7091,  0.0621,  0.4862,\n",
              "           0.2383,  0.5455,  0.2450,  0.4539, -0.4588, -0.6625, -0.3153,  0.7257,\n",
              "           0.8921,  0.2491,  0.1456,  0.0130, -0.2261, -0.3224,  0.0517, -0.1113,\n",
              "           0.7909,  0.5986, -0.4915,  0.2748, -0.9137,  0.6437, -0.2932, -0.8105,\n",
              "          -0.7410, -0.9058, -0.0278,  0.1369, -0.8983, -0.2540, -0.1192,  0.6502],\n",
              "         [-0.0761, -0.1996,  0.2662, -0.0714, -0.5771, -0.6263, -0.2824, -0.3926,\n",
              "          -0.3947,  0.3267, -0.4514, -0.3072,  0.3663, -0.3814, -0.6125, -0.6617,\n",
              "          -0.7295,  0.6367, -0.4549, -0.1412,  0.4085,  0.8876,  0.4748,  0.2899,\n",
              "           0.4694,  0.4442, -0.2764, -0.1411,  0.6763, -0.0413, -0.3856,  0.5361,\n",
              "           0.3769,  0.0301, -0.4259, -0.2020,  0.1302, -0.4192,  0.5856,  0.4501,\n",
              "           0.1785,  0.6954,  0.2775,  0.3380, -0.2387,  0.4121, -0.1584, -0.4684,\n",
              "          -0.4801,  0.0067,  0.8419,  0.4035, -0.0748, -0.3850, -0.3300, -0.3024,\n",
              "          -0.1802,  0.7343, -0.0440, -0.2161, -0.2688, -0.0465, -0.2745,  0.0087],\n",
              "         [-0.0773,  0.1329, -0.0224,  0.9245, -0.0779, -0.4749,  0.2162,  0.1350,\n",
              "          -0.5610,  0.0418,  0.4945, -0.0918, -0.3456, -0.4019,  0.1548, -0.5725,\n",
              "           0.5144, -0.3629, -0.6166, -0.3278,  0.2076,  0.7443, -0.3559, -0.6537,\n",
              "          -0.3929, -0.2408,  0.6433, -0.7057, -0.8718, -0.6976, -0.3789,  0.0124,\n",
              "          -0.1608,  0.7170, -0.4690, -0.2210,  0.1890, -0.4555,  0.0242,  0.6275,\n",
              "           0.3629,  0.3088, -0.1860, -0.4875, -0.1977, -0.7039,  0.6487, -0.2593,\n",
              "          -0.6847, -0.2143,  0.5878, -0.6811, -0.4205, -0.4598,  0.7939,  0.1018,\n",
              "           0.7180,  0.2828, -0.7109, -0.4846, -0.4304, -0.0950, -0.4774,  0.0614],\n",
              "         [-0.8925,  0.6591, -0.3652, -0.6024, -0.1700, -0.5980,  0.5166, -0.0686,\n",
              "          -0.6109, -0.2104,  0.2591,  0.6992, -0.3233,  0.2907,  0.6930, -0.6401,\n",
              "          -0.6031, -0.9009, -0.5451, -0.0200,  0.6066,  0.2254,  0.8781,  0.4153,\n",
              "           0.0242, -0.0036,  0.5587,  0.0267, -0.6786,  0.3948, -0.5311,  0.0198,\n",
              "          -0.0342, -0.0750,  0.1402, -0.6536,  0.5951, -0.1378,  0.1223,  0.1082,\n",
              "           0.1463,  0.1664,  0.2174,  0.5950, -0.7339, -0.7382, -0.3341, -0.4593,\n",
              "           0.1970,  0.4353, -0.7015, -0.1135,  0.5562,  0.7719,  0.0490,  0.4547,\n",
              "           0.4683,  0.1999, -0.8541, -0.2395,  0.4831, -0.8160, -0.7907, -0.3577],\n",
              "         [-0.4906, -0.1184, -0.0903, -0.2817, -0.4793,  0.4200,  0.6410, -0.4409,\n",
              "          -0.6433, -0.2080, -0.3145,  0.7632,  0.0074,  0.6711, -0.8635, -0.2014,\n",
              "          -0.6031, -0.6472, -0.3324, -0.4441, -0.2662, -0.3911,  0.2048,  0.1462,\n",
              "          -0.5956,  0.7516, -0.5441,  0.4695, -0.3879,  0.7566,  0.6975, -0.0663,\n",
              "           0.4950,  0.0349, -0.5491,  0.2187, -0.3332, -0.1834,  0.7627,  0.2699,\n",
              "          -0.7334,  0.2017,  0.1168,  0.5946, -0.2540, -0.5599, -0.5150, -0.6151,\n",
              "          -0.0304,  0.8593,  0.2397, -0.4498,  0.2274,  0.1437,  0.4068,  0.7875,\n",
              "           0.8526,  0.8418,  0.6152,  0.3371, -0.1879, -0.4013,  0.3224,  0.0781]],\n",
              "        grad_fn=<SqueezeBackward1>),\n",
              " tensor([[-0.4906, -0.1184, -0.0903, -0.2817, -0.4793,  0.4200,  0.6410, -0.4409,\n",
              "          -0.6433, -0.2080, -0.3145,  0.7632,  0.0074,  0.6711, -0.8635, -0.2014,\n",
              "          -0.6031, -0.6472, -0.3324, -0.4441, -0.2662, -0.3911,  0.2048,  0.1462,\n",
              "          -0.5956,  0.7516, -0.5441,  0.4695, -0.3879,  0.7566,  0.6975, -0.0663,\n",
              "           0.4950,  0.0349, -0.5491,  0.2187, -0.3332, -0.1834,  0.7627,  0.2699,\n",
              "          -0.7334,  0.2017,  0.1168,  0.5946, -0.2540, -0.5599, -0.5150, -0.6151,\n",
              "          -0.0304,  0.8593,  0.2397, -0.4498,  0.2274,  0.1437,  0.4068,  0.7875,\n",
              "           0.8526,  0.8418,  0.6152,  0.3371, -0.1879, -0.4013,  0.3224,  0.0781]],\n",
              "        grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)[0].shape"
      ],
      "metadata": {
        "id": "3QLDcKyVGaGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b17ddb-3f0e-4650-b439-ed2aeab5fd71"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = y(a)[1]"
      ],
      "metadata": {
        "id": "ttzMQQmjGaI0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64, 330)"
      ],
      "metadata": {
        "id": "d8A5MHJFGaNj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z(b).shape"
      ],
      "metadata": {
        "id": "IgUG53rCGaQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bdb3f1-ebae-4309-bdee-89747415669d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 330])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "Yitmh5g7GaVD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "27GUL5MWGaXj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "0ABukjc5Gaf7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64, batch_first=True)\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1,6)\n",
        "print(\"shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"shape of b:\", b.shape)\n",
        "c, d = y(b)\n",
        "print(\"shape of c:\", c.shape)\n",
        "print(\"shape of d:\", d.shape)\n",
        "\n",
        "e = z(d.squeeze(0))\n",
        "\n",
        "print(\"shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W6TF6RCUNUR",
        "outputId": "54eec5b7-6c1e-49f8-b0ed-9cb47e2a5811"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a: torch.Size([1, 6])\n",
            "shape of b: torch.Size([1, 6, 50])\n",
            "shape of c: torch.Size([1, 6, 64])\n",
            "shape of d: torch.Size([1, 1, 64])\n",
            "shape of e: torch.Size([1, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(question)\n",
        "\n",
        "    # output = output.view(-1, output.size(-1))\n",
        "    # answer = answer.view(-1)\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(output, answer[0])\n",
        "\n",
        "    # gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "id": "Za8iVS8aGak0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60418217-fdbc-4538-90a9-4bd7c90de1a2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 523.346014\n",
            "Epoch: 2, Loss: 454.895668\n",
            "Epoch: 3, Loss: 374.717069\n",
            "Epoch: 4, Loss: 313.074487\n",
            "Epoch: 5, Loss: 261.616409\n",
            "Epoch: 6, Loss: 213.420938\n",
            "Epoch: 7, Loss: 169.804452\n",
            "Epoch: 8, Loss: 132.094417\n",
            "Epoch: 9, Loss: 101.766497\n",
            "Epoch: 10, Loss: 78.171867\n",
            "Epoch: 11, Loss: 59.931057\n",
            "Epoch: 12, Loss: 47.566643\n",
            "Epoch: 13, Loss: 38.026240\n",
            "Epoch: 14, Loss: 31.111705\n",
            "Epoch: 15, Loss: 25.501053\n",
            "Epoch: 16, Loss: 21.503536\n",
            "Epoch: 17, Loss: 18.172937\n",
            "Epoch: 18, Loss: 15.369568\n",
            "Epoch: 19, Loss: 13.354370\n",
            "Epoch: 20, Loss: 11.721244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold = 0.5):\n",
        "  # convert text to indices\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # convert to tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max probs\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value<threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "EuPj_yhdGanc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the largest planet in our solar system?\")"
      ],
      "metadata": {
        "id": "lJEe5RWKGar1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11500b3-b182-400c-f9d3-6b5ef0bd8762"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jupiter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())[7]"
      ],
      "metadata": {
        "id": "d5hfYL_qGauc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "50e9b72d-24de-4418-fa61-7fcea25a9207"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fsmh18OjHek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}